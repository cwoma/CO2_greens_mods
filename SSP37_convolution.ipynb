{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cftime\n",
    "import dask\n",
    "import xarrayutils\n",
    "import cartopy.crs as ccrs\n",
    "from xmip.preprocessing import combined_preprocessing\n",
    "from xmip.preprocessing import replace_x_y_nominal_lat_lon\n",
    "from xmip.drift_removal import replace_time\n",
    "from xmip.postprocessing import concat_experiments\n",
    "import xmip.drift_removal as xm_dr\n",
    "import xmip as xm\n",
    "import xesmf as xe\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import utils\n",
    "import cf_xarray as cfxr\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import scipy.signal as signal\n",
    "from scipy import stats\n",
    "from datetime import timedelta\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import cmocean\n",
    "import cmocean.cm as cmo\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dask.config.set at 0x7f3718706190>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dask.config.set(**{'array.slicing.split_large_chunks': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_ds = xr.open_dataset('Outputs/G_ds.nc4')['__xarray_dataarray_variable__']\n",
    "G_mean_ds = xr.open_dataset('Outputs/G_mean_ds.nc4')['__xarray_dataarray_variable__']\n",
    "\n",
    "G_CDR_ds = xr.open_dataset('Outputs/G_cdr_ds.nc4')['__xarray_dataarray_variable__']\n",
    "G_CDR_mean_ds = xr.open_dataset('Outputs/G_cdr_mean_ds.nc4')['__xarray_dataarray_variable__']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_ds = xr.concat([G_ds, -G_CDR_ds], pd.Index(['pulse','cdr'], name = 'pulse_type'))\n",
    "G_mean_ds = xr.concat([G_mean_ds, -G_CDR_mean_ds], pd.Index(['pulse','cdr'], name = 'pulse_type'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_ds.name = 'G[tas]'\n",
    "G_mean_ds.name = 'G[tas]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_ds = G_ds.rename({'year':'s'})\n",
    "G_mean_ds = G_mean_ds.rename({'year':'s'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes:\n",
    "\n",
    "GFDL: 1pct and esm pi-control start from year 0001\n",
    "\n",
    "UKESM1: 1pct starts in 1850 and pi-control starts in 1960, move 1pct to start in 1960\n",
    "\n",
    "MIROC: both start from 1850\n",
    "\n",
    "NORESM2: 1pct from 0001 pi-control from 1600-- move 1pct to 1600\n",
    "\n",
    "ACCESS: 1pct and pi-control from 0101\n",
    "\n",
    "CANESM5_r1p2: 1pct 1850, pi-control 5550, move 1pct to 5550\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run_SSP37_dict = {'GFDL': 'GFDL-ESM4_ssp370_r1i1p1f1**'}\n",
    "model_run_historical_dict = {'GFDL': 'GFDL-ESM4_historical_r1i1p1f1**'}\n",
    "model_run_control_dict = {'GFDL': 'GFDL-ESM4_piControl_r1i1p1f1**'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_color = utils.model_color\n",
    "type_color = utils.type_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define our output grid size\n",
    "\n",
    "ds_out = xr.Dataset(\n",
    "    {\n",
    "        \"lat\": ([\"lat\"], np.arange(-89.5, 90.5, 1.0)),\n",
    "        \"lon\": ([\"lon\"], np.arange(0, 360, 1)),\n",
    "        \"lat_b\": ([\"lat_b\"], np.arange(-90.,91.,1.0)),\n",
    "        \"lon_b\":([\"lon_b\"], np.arange(.5, 361.5, 1.0))\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = utils.find_area(ds_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GFDL\n",
      "tas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cwomack/.conda/envs/gchp/lib/python3.9/site-packages/xesmf/frontend.py:555: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  ds_out = xr.apply_ufunc(\n"
     ]
    }
   ],
   "source": [
    "tas_SSP37 = {}\n",
    "tas_pictrl = {}\n",
    "\n",
    "for m in model_run_SSP37_dict.keys():\n",
    "    print(m)\n",
    "    print('tas')\n",
    "    tas_past = xr.open_mfdataset(f'cmip6_data/historical/tas_Amon_{model_run_historical_dict[m]}',  use_cftime=True) #kg/m2/s\n",
    "    tas_future = xr.open_mfdataset(f'cmip6_data/SSP37/tas_Amon_{model_run_SSP37_dict[m]}',  use_cftime=True) #kg/m2/s\n",
    "    tas_SSP37[m] = xr.concat([tas_past,tas_future],dim = 'time')\n",
    "    \n",
    "    lat_corners = cfxr.bounds_to_vertices(tas_SSP37[m].isel(time = 0)['lat_bnds'], \"bnds\", order=None)\n",
    "    lon_corners = cfxr.bounds_to_vertices(tas_SSP37[m].isel(time = 0)['lon_bnds'], \"bnds\", order=None)\n",
    "    tas_SSP37[m] = tas_SSP37[m].assign(lon_b=lon_corners, lat_b=lat_corners)\n",
    "    tas_SSP37[m] = utils._regrid_ds(tas_SSP37[m], ds_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GFDL\n",
      "tas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cwomack/.conda/envs/gchp/lib/python3.9/site-packages/xesmf/frontend.py:555: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  ds_out = xr.apply_ufunc(\n"
     ]
    }
   ],
   "source": [
    "for m in model_run_control_dict.keys():\n",
    "    print(m)\n",
    "    print('tas')\n",
    "    tas_pictrl[m] = xr.open_mfdataset(f'cmip6_data/piControl/tas_Amon_{model_run_control_dict[m]}',  use_cftime=True) #kg/m2/s\n",
    "    lat_corners = cfxr.bounds_to_vertices(tas_pictrl[m].isel(time = 0)['lat_bnds'], \"bnds\", order=None)\n",
    "    lon_corners = cfxr.bounds_to_vertices(tas_pictrl[m].isel(time = 0)['lon_bnds'], \"bnds\", order=None)\n",
    "    tas_pictrl[m] = tas_pictrl[m].assign(lon_b=lon_corners, lat_b=lat_corners)\n",
    "    tas_pictrl[m] = utils._regrid_ds(tas_pictrl[m], ds_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align time between model runs and pi control runs\n",
    "m = 'GFDL'\n",
    "tas_SSP37[m]['time'] = tas_SSP37[m]['time'] - timedelta(365*1849)\n",
    "tas_pictrl[m] = tas_pictrl[m].loc[dict(time = slice(tas_pictrl[m]['time'].min(), tas_SSP37[m]['time'].max()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GFDL GFDL\n"
     ]
    }
   ],
   "source": [
    "dif_SSP37 = {}\n",
    "for m1 in model_run_SSP37_dict.keys():\n",
    "    if m1 == 'UKESM1_r1' or m1 == 'UKESM1_r2' or m1 == 'UKESM1_r3' or m1 == 'UKESM1_r4':\n",
    "        m2 = 'UKESM1_r1'\n",
    "    elif m1 == 'CANESM5_r1p1' or m1 == 'CANESM5_r2p1' or m1 == 'CANESM5_r3p1':\n",
    "         m2 = 'CANESM5_r1p1'\n",
    "    elif m1 == 'CANESM5_r1p2' or m1 == 'CANESM5_r2p2' or m1 == 'CANESM5_r3p2':\n",
    "         m2 = 'CANESM5_r1p2'\n",
    "    else:\n",
    "        m2 = m1\n",
    "    print(m1, m2)\n",
    "    \n",
    "    dif_SSP37[m1] = tas_SSP37[m1] - tas_pictrl[m2]\n",
    "\n",
    "    if len(dif_SSP37[m1]['time']) > 3000:  #hack to get the time stamping to work, should find better fix\n",
    "        periods = 3000\n",
    "    else:\n",
    "        periods = len(dif_SSP37[m1]['time'])\n",
    "        \n",
    "    times = pd.date_range('2000', periods= periods, freq='MS')\n",
    "    weights = times.shift(1, 'MS') - times\n",
    "    weights = xr.DataArray(weights, [('time', dif_SSP37[m1]['time'][:periods].values)]).astype('float')\n",
    "    dif_SSP37[m1] =  (dif_SSP37[m1] * weights).groupby('time.year').sum('time')/weights.groupby('time.year').sum('time')\n",
    "\n",
    "    dif_SSP37[m1]['year'] = range(len(dif_SSP37[m1]['year']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in dif_SSP37.keys():\n",
    "    dif_SSP37[m] = dif_SSP37[m].drop('height')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rid of height and limit the time to the length of the GF\n",
    "for m1 in ['UKESM1_r1', 'UKESM1_r2', 'UKESM1_r3', 'UKESM1_r4', 'NORESM2',\n",
    "       'GFDL', 'MIROC', 'CANESM5_r1p2', 'CANESM5_r2p2', 'ACCESS', 'CANESM5_r3p2']:\n",
    "    \n",
    "    for t in ['pulse','cdr']:\n",
    "        if m1 == 'UKESM1_r1' or m1 == 'UKESM1_r2' or m1 == 'UKESM1_r3' or m1 == 'UKESM1_r4':\n",
    "            m2 = 'UKESM1_r1'\n",
    "        elif m1 == 'CANESM5_r1p1' or m1 == 'CANESM5_r2p1' or m1 == 'CANESM5_r3p1':\n",
    "             m2 = 'CANESM5_r1p1'\n",
    "        elif m1 == 'CANESM5_r1p2' or m1 == 'CANESM5_r2p2' or m1 == 'CANESM5_r3p2':\n",
    "             m2 = 'CANESM5_r1p2'\n",
    "        else:\n",
    "            m2 = m1\n",
    "        \n",
    "        length = len(G_ds.sel(model = m2, pulse_type = t).dropna(dim = 's')['s'])\n",
    "        dif_SSP37[m] = dif_SSP37[m].sel(year = slice(0,length))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dif_SSP37 = xr.concat([dif_SSP37[m] for m in dif_SSP37.keys()], pd.Index([m for m in dif_SSP37.keys()], name='model'), coords='minimal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dif = xr.concat([ds_dif_SSP37], pd.Index(['SSP37'], name='experiment'), coords='minimal')\n",
    "ds_dif = ds_dif.rename({'year':'s'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emissions profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "emis_profile_SSP37 = xr.open_dataset(f'SSP37_emis_profile_full.nc4')\n",
    "emis_profile_SSP37 = emis_profile_SSP37.rename({'__xarray_dataarray_variable__':'emis'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "emis_profile = xr.concat([emis_profile_SSP37], pd.Index(['SSP37'], name='experiment'), coords='minimal')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define our Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define our weights for models (grouping UKESM and CANESM realizations)\n",
    "model_weights = {'GFDL': 1}\n",
    "model_weights = xr.DataArray(\n",
    "    data=list(model_weights.values()),\n",
    "    dims=[\"model\"],\n",
    "    coords=dict(\n",
    "        model=([\"model\"], list(model_weights.keys()))\n",
    "    ),\n",
    "    attrs=dict(\n",
    "        description=\"weights for models\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_model_weights = {'GFDL': 1}\n",
    "G_model_weights = xr.DataArray(\n",
    "    data=list(G_model_weights.values()),\n",
    "    dims=[\"model\"],\n",
    "    coords=dict(\n",
    "        model=([\"model\"], list(G_model_weights.keys()))\n",
    "    ),\n",
    "    attrs=dict(\n",
    "        description=\"weights for Green's function\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PiCtrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#combine our picontrol data into one dataset, normalizing the time to year 0\n",
    "pictrl = {}\n",
    "for m in tas_pictrl.keys():    \n",
    "    times = tas_pictrl[m].time.get_index('time')\n",
    "    weights = times.shift(-1, 'MS') - times.shift(1, 'MS')\n",
    "    weights = xr.DataArray(weights, [('time', tas_pictrl[m]['time'].values)]).astype('float')\n",
    "    pictrl[m] =  (tas_pictrl[m] * weights).groupby('time.year').sum('time')/weights.groupby('time.year').sum('time')\n",
    "    pictrl[m]['year'] = pictrl[m]['year'] - pictrl[m]['year'][0] \n",
    "    \n",
    "for m in pictrl.keys():\n",
    "    pictrl[m] = pictrl[m].drop('height')\n",
    "ds_pictrl = xr.concat([pictrl[m] for m in pictrl.keys()], pd.Index([m for m in pictrl.keys()], name='model'), coords='minimal')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Mean Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.06 s, sys: 805 ms, total: 4.87 s\n",
      "Wall time: 4.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "GF = G_ds.weighted(A).mean(dim = ['lat','lon'])\n",
    "\n",
    "conv_mean = {}\n",
    "for exp in ['SSP37']:\n",
    "    conv_mean[exp] = {}\n",
    "    for m1 in ['GFDL']:\n",
    "        conv_mean[exp][m1] = {}\n",
    "        for t in ['pulse','cdr']:\n",
    "            if m1 == 'UKESM1_r1' or m1 == 'UKESM1_r2' or m1 == 'UKESM1_r3' or m1 == 'UKESM1_r4':\n",
    "                m2 = 'UKESM1_r1'\n",
    "            else:\n",
    "                m2 = m1\n",
    "            conv_mean[exp][m1][t] = signal.convolve( np.array(GF.sel(model = m2, pulse_type = t).dropna(dim = 's')), np.array(emis_profile.sel(model = m1, experiment = exp)['emis']),'full')\n",
    "            conv_mean[exp][m1][t] = utils.np_to_xr_mean(conv_mean[exp][m1][t], GF.sel(model = m2, pulse_type = t), emis_profile.sel(model = m1, experiment = exp))\n",
    "            length = len(G_ds.weighted(A).mean(dim = ['lat','lon']).dropna(dim = 's')['s'])\n",
    "            conv_mean[exp][m1][t] = conv_mean[exp][m1][t][:length]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to dataset\n",
    "\n",
    "conv_dict = {}\n",
    "for exp in conv_mean.keys():\n",
    "    conv_dict[exp] = {}\n",
    "    for m in conv_mean[exp].keys():\n",
    "        conv_dict[exp][m] = xr.concat([conv_mean[exp][m][t] for t in conv_mean[exp][m].keys()], pd.Index([t for t in conv_mean[exp][m].keys()], name='pulse_type'), coords='minimal')\n",
    "for exp in conv_mean.keys():\n",
    "    conv_dict[exp] = xr.concat([conv_dict[exp][m] for m in conv_mean[exp].keys()], pd.Index([m for m in conv_mean[exp].keys()], name='model'), coords='minimal')\n",
    "conv_mean_ds = xr.concat([conv_dict[exp] for exp in conv_dict.keys()], pd.Index([exp for exp in conv_dict.keys()], name='experiment'), coords='minimal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reindex_df(df, weight_col):\n",
    "    \"\"\"expand the dataframe to prepare for resampling\n",
    "    result is 1 row per count per sample\"\"\"\n",
    "    df = df.reindex(df.index.repeat(df[weight_col]))\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return(df)\n",
    "\n",
    "data = {'mean': conv_mean_ds.sel(experiment = 'SSP37').mean(dim = ['pulse_type']).sel(s = slice(60,80)).mean(dim = ['s']).values,\n",
    "        'model': conv_mean_ds.model.values,\n",
    "        'count': [12]}\n",
    "df_SSP37_emulator = pd.DataFrame(data)\n",
    "df_SSP37_emulator = reindex_df(df_SSP37_emulator, weight_col = 'count')\n",
    "\n",
    "data = {'mean': ds_dif.where(ds_dif['model'].isin(model_weights.model.values), drop = True).sel(experiment = 'SSP37').sel(s = slice(60,80)).weighted(A).mean(dim = ['s', 'lon','lat'])['tas'].values,\n",
    "        'model': ds_dif.where(ds_dif['model'].isin(model_weights.model.values), drop = True).sel(experiment = 'SSP37').model.values,\n",
    "        'count': [12]}\n",
    "\n",
    "df_SSP37_model = pd.DataFrame(data)\n",
    "df_SSP37_model = reindex_df(df_SSP37_model, weight_col = 'count')\n",
    "\n",
    "#######ZEC############\n",
    "\n",
    "data = {'mean': (conv_mean_ds.sel(experiment = 'SSP37').where(conv_mean_ds['model'].isin(list(model_run_SSP37_dict.keys())), drop = True).mean(dim = 'pulse_type').sel(\n",
    "                                                                s = slice(80-10, 80+10)).mean(dim = 's').weighted(A).mean(dim = ['lat','lon']) - \n",
    "                    conv_mean_ds.sel(experiment = 'SSP37').where(conv_mean_ds['model'].isin(list(model_run_SSP37_dict.keys())), drop = True).mean(dim = 'pulse_type').sel(s = 65).weighted(A).mean(dim = ['lat','lon'])).values,\n",
    "        'model': conv_mean_ds.where(conv_mean_ds['model'].isin(list(model_run_SSP37_dict.keys())), drop = True).model.values,\n",
    "        'count': [12]}\n",
    "\n",
    "df_zec_emulator_model = pd.DataFrame(data)\n",
    "df_zec_emulator_model = reindex_df(df_zec_emulator_model, weight_col = 'count')\n",
    "\n",
    "data = {'mean': (ds_dif.where(ds_dif['model'].isin(list(model_run_SSP37_dict.keys())), drop = True).sel(experiment = 'SSP37').sel(\n",
    "                                                                s = slice(80-10, 80+10)).mean(dim = 's').weighted(A).mean(dim = ['lat','lon']) - \n",
    "                    ds_dif.where(ds_dif['model'].isin(list(model_run_SSP37_dict.keys())), drop = True).sel(experiment = 'SSP37').sel(s = 65).weighted(A).mean(dim = ['lat','lon']))['tas'].values,\n",
    "        \n",
    "        'model': ds_dif.where(ds_dif['model'].isin(list(model_run_SSP37_dict.keys())), drop = True).sel(experiment = 'SSP37').model.values,\n",
    "        'count': [12]}\n",
    "\n",
    "df_zec_cmip_model = pd.DataFrame(data)\n",
    "df_zec_cmip_model = reindex_df(df_zec_cmip_model, weight_col = 'count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000gtc\n",
      "UKESM1_r1 UKESM1_r1\n",
      "UKESM1_r1 UKESM1_r1\n",
      "UKESM1_r2 UKESM1_r1\n",
      "UKESM1_r2 UKESM1_r1\n",
      "UKESM1_r3 UKESM1_r1\n",
      "UKESM1_r3 UKESM1_r1\n",
      "UKESM1_r4 UKESM1_r1\n",
      "UKESM1_r4 UKESM1_r1\n",
      "NORESM2 NORESM2\n",
      "NORESM2 NORESM2\n",
      "MIROC MIROC\n",
      "MIROC MIROC\n",
      "CANESM5_r1p2 CANESM5_r1p2\n",
      "CANESM5_r1p2 CANESM5_r1p2\n",
      "CANESM5_r2p2 CANESM5_r2p2\n",
      "CANESM5_r2p2 CANESM5_r2p2\n",
      "ACCESS ACCESS\n",
      "ACCESS ACCESS\n",
      "CANESM5_r3p2 CANESM5_r3p2\n",
      "CANESM5_r3p2 CANESM5_r3p2\n",
      "1pct\n",
      "UKESM1_r1 UKESM1_r1\n",
      "UKESM1_r1 UKESM1_r1\n",
      "UKESM1_r2 UKESM1_r1\n",
      "UKESM1_r2 UKESM1_r1\n",
      "UKESM1_r3 UKESM1_r1\n",
      "UKESM1_r3 UKESM1_r1\n",
      "UKESM1_r4 UKESM1_r1\n",
      "UKESM1_r4 UKESM1_r1\n",
      "NORESM2 NORESM2\n",
      "NORESM2 NORESM2\n",
      "GFDL GFDL\n",
      "GFDL GFDL\n",
      "MIROC MIROC\n",
      "MIROC MIROC\n",
      "CANESM5_r1p2 CANESM5_r1p2\n",
      "CANESM5_r1p2 CANESM5_r1p2\n",
      "CANESM5_r2p2 CANESM5_r2p2\n",
      "CANESM5_r2p2 CANESM5_r2p2\n",
      "ACCESS ACCESS\n",
      "ACCESS ACCESS\n",
      "CANESM5_r3p2 CANESM5_r3p2\n",
      "CANESM5_r3p2 CANESM5_r3p2\n",
      "CPU times: user 21.6 s, sys: 24.5 s, total: 46.1 s\n",
      "Wall time: 46.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "GF = G_ds\n",
    "\n",
    "conv = {}\n",
    "for exp in ['SSP37']:\n",
    "    print(exp)\n",
    "    conv[exp] = {}\n",
    "    if exp == 'SSP37':\n",
    "        model_list = [CANESM5_r2p2', 'ACCESS', 'CANESM5_r3p2',]\n",
    "    elif exp == '1pct':\n",
    "        model_list = ['UKESM1_r1', 'UKESM1_r2', 'UKESM1_r3', 'UKESM1_r4', 'NORESM2', 'GFDL', 'MIROC', 'CANESM5_r1p2', 'CANESM5_r2p2', 'ACCESS', 'CANESM5_r3p2',]\n",
    "    for m1 in model_list:\n",
    "        conv[exp][m1] = {}\n",
    "        for t in ['pulse','cdr']:\n",
    "            if m1 == 'UKESM1_r1' or m1 == 'UKESM1_r2' or m1 == 'UKESM1_r3' or m1 == 'UKESM1_r4':\n",
    "                m2 = 'UKESM1_r1'\n",
    "            else:\n",
    "                m2 = m1\n",
    "            print(m1, m2)\n",
    "            conv[exp][m1][t] = signal.convolve(np.array(GF.sel(model = m2, pulse_type = t).dropna(dim = 's')), \n",
    "                                               np.array(emis_profile.sel(model = m1, experiment = exp)['emis'])[~np.isnan(np.array(emis_profile.sel(model = m1, experiment = exp)['emis']))][..., None, None],\n",
    "                                               'full')\n",
    "            conv[exp][m1][t] = utils.np_to_xr(conv[exp][m1][t], GF.sel(model = m2, pulse_type = t), emis_profile.sel(model = m1, experiment = exp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to dataset\n",
    "\n",
    "conv_dict = {}\n",
    "for exp in conv.keys():\n",
    "    conv_dict[exp] = {}\n",
    "    for m in conv[exp].keys():\n",
    "        conv_dict[exp][m] = xr.concat([conv[exp][m][t] for t in conv[exp][m].keys()], pd.Index([t for t in conv[exp][m].keys()], name='pulse_type'), coords='minimal')\n",
    "for exp in conv.keys():\n",
    "    conv_dict[exp] = xr.concat([conv_dict[exp][m] for m in conv[exp].keys()], pd.Index([m for m in conv[exp].keys()], name='model'), coords='minimal')\n",
    "conv_ds = xr.concat([conv_dict[exp] for exp in conv_dict.keys()], pd.Index([exp for exp in conv_dict.keys()], name='experiment'), coords='minimal')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_mean_ds.to_netcdf('Outputs/conv_mean_ds.nc4')\n",
    "\n",
    "conv_ds.to_netcdf('Outputs/conv_ds.nc4')\n",
    "\n",
    "emis_profile.to_netcdf('Outputs/emis_profile.nc4')\n",
    "\n",
    "ds_dif.to_netcdf('Outputs/ds_dif.nc4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pictrl.to_netcdf('Outputs/ds_pictrl.nc4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gchp",
   "language": "python",
   "name": "gchp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
